---
title: "Internship presentation"
subtitle: "Tree object detection using airborne images and LiDAR point clouds"
author: "Alexandre Bry"
incremental: true
slide-level: 2
reference-location: document
format:
  revealjs:
    transition: slide
    theme: [default, _extensions/grantmcdermott/clean/clean.scss]
# nice themes: blood, dark, default, serif,
    slide-number: true
    show-slide-number: all
    css: styles.css
  # beamer:
  #   theme: AnnArbor
  #   colortheme: lily
---

# Introduction

::: {.notes}

Ce qu'il est important de faire ressortir est :
- le contexte du travail, le problème sur lequel vous avez travaillé et l’état de l'art
- la solution (ou solution partielle) que vous avez proposée, mise en perspective avec l’état de l'art
- les problèmes que votre travail laisse ouverts, qui pourraient constituer un point de départ pour une continuation, ou sur lesquels vous allez travailler pendant la période de stage restante.

:::

## Goal of the internship

![Deep learning model synthesis](figures/diagrams/Synthetic_diagram/Synthetic_diagram.png)

## Additional goals

- Find all trees, including covered trees
- Extract more information from the point cloud than its surface

::: {.notes}

These two goals are related to each other.

:::

# State-of-the-art

## YOLOv8 model {.scrollable}

::: {.center-xy}

![The architecture of YOLOv8 ([https://github.com/ultralytics/ultralytics/issues/189](https://github.com/ultralytics/ultralytics/issues/189))](figures/images/YOLOv8-architecture.jpg){height=500px}

:::

::: {.notes}

- SOTA
- Fast and reliable
- One-shot detection
- Predicts boxes and classes 

:::

## AMF GD YOLOv8 {.scrollable}

::: {.center-xy}

![The architecture of AMF GD YOLOv8](figures/diagrams/Modified_AMF_GD_YOLOv8.png){height=350px}

:::

::: {.notes}
- Adaptation of YOLOv8 for multiple inputs
- Fusion of features
- Same detection layers
:::

## NEON dataset {.scrollable}

:::: {.columns .center-y}

::: {.column}
![Example of an annotated forest in the NEON dataset ([https://visualize.idtrees.org/](https://visualize.idtrees.org/))](figures/images/NEON_example.png){width="100%"}
:::

::: {.column .nonincremental}
:::: {.fragment}
- **Creation process**:
  - 10k hand-annotated
  - 30M auto-annotated
::::
:::: {.fragment}
- **Strengths**:
  - Diversity
  - Tree species
::::
:::: {.fragment}
- **Weaknesses**:
  - Image quality
  - Covered trees
::::
:::

::::

# My dataset of trees

## Data available in the Netherlands

::: {.nonincremental}
::: {.fragment}
- **"Raw" data**:
  - Point cloud
  - RGB images
  - CIR images
:::
::: {.fragment}
- **Trees**:
  - Public trees handled by municipalities
:::
:::

::: {.notes}
Reasons for choosing the Netherlands data:

- Quality
- Consistency
:::

## Data inconsistencies

::: {.columns}
::: {.column .fragment width=40%}
### Temporal shift

::: {.nonincremental}
- Cut trees
- New small trees
- Replaced trees
:::

:::
::: {.column .fragment width=60%}
### Location shift

::: {layout="[[1, 1], [1, 1]]" }
![RGB](figures/images/Data_shift/RGB_image.png){width=230px}

![Infrared](figures/images/Data_shift/CIR_image.png){width=230px}

![CHM](figures/images/Data_shift/CHM_all_color.png){width=230px}

![LiDAR](figures/images/Data_shift/LiDAR.png){width=230px}
:::

:::
:::

::: {.notes}
- Dates:
  - Images from 2023
  - Point clouds from 2020
- Non-orthogonal images:
  - Bigger shift when further from flight lines
  - Bigger shift when higher flight altitude
  - Different shift with different flight lines
:::

## Content

:::: {.columns}

::: {.column .nonincremental width=40% .fragment}
### Class labels

- Tree
- Tree_LiDAR (cut trees)
- Tree_RGB (planted trees)
- Tree_low_hard (covered trees)
:::

::: {.column width=60% .fragment}
### Spatial extent

![All the trees in the dataset](figures/images/Full_dataset/With_boxes.png){height=500}
:::

::: {.notes}
- Link with shifts
- Over a 1 km × 1 km area
- 2668 trees
:::

::::

## Annotation material

::: {layout="[[1, 1], [1, 1]]" }
![RGB images](figures/images/Annotation_setup/RGB_image.png){height=230px}

![Point cloud from above, colored by height, between 2 m and 20 m](figures/images/Annotation_setup/LiDAR_2_20.png){height=230px}

![Point cloud in 3D](figures/images/Annotation_setup/LiDAR_3D.png){height=230px}

![Google StreetView images](figures/images/Annotation_setup/StreetView.png){height=230px}
:::

# Experiments

## CHM layers

:::: {.columns .center-y}

::: {.column .fragment fragment-index=3}
::: {layout="[[1, 1], [1, 1]]" }
![Height: 2 m to 30 m](figures/images/CHM_layers/Point_cloud_2_30.png){height=230px}

![Height: 2 m to 20 m](figures/images/CHM_layers/Point_cloud_2_20.png){height=230px}

![Height: 2 m to 13 m](figures/images/CHM_layers/Point_cloud_2_13.png){height=230px}

![Height: 2 m to 8 m](figures/images/CHM_layers/Point_cloud_2_8.png){height=230px}
:::
:::

::: {.column .nonincremental}
::: {.fragment fragment-index=1}
- **Goals**:
  - Use more data from the point cloud, including trunks
  - Find covered trees
:::
::: {.fragment fragment-index=2}
- **Idea**: create different levels of CHM
:::
:::

::::

::: {.notes}
- Different ways of extracting point clouds
- Simple solution to get access to the lower parts of the point cloud
:::

## Random input drop

:::: {.columns .center-y}

::: {.column width=40%}
- **Goal**: push the model to use RGB *and* CHM
- **Idea**: randomly drop either RGB *or* CHM
- Combined with random channel drop
:::

::: {.column width=60% .fragment}
![](figures/images/Quarto_generated/fig-training-parameters-drop.svg)
:::

::::

# Potential future improvements

## Dataset

::: {.nonincremental}
::: {.fragment}
- **More data**:
  - Surface
  - Diversity
:::
::: {.fragment}
- **Improved annotations**:
  - Species
  - Precise polygons/masks
:::
::: {.fragment}
- **Artificial annotations**:
  - Classical techniques
  - Municipalities
:::
:::

## Training instability

::: {.nonincremental}
::: {.fragment}
- **Larger dataset**:
  - More trees
  - More diverse environments
  - Better augmentations (for CHM as well)
:::
::: {.fragment}
- **Other loss functions?**
:::
::: {.fragment}
- **Regularization techniques**:
  - Weight decay
  - Batch normalization
:::
:::

::: {.notes}
- Makes deductions difficult
- Already using:
  - Batch accumulation
  - Early stopping
:::

# Conclusion

## Conclusion

::: {.nonincremental}
::: {.fragment}
- **New tree detection dataset**:
  - RGB and infrared images
  - Point clouds
  - Trees bounding boxes (including covered trees)
:::
::: {.fragment}
- **Promising model**:
  - Based on YOLOv8 backbone
  - Could potentially find covered tress
:::
:::